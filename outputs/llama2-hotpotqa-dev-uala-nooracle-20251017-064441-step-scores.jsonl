{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3687, "step_index": 1, "tentative_answer": "The Double Life of Veronique]", "uncertainty": 2.19, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3687, "step_index": 2, "tentative_answer": "The Secret Garden]", "uncertainty": 1.61, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3687, "step_index": 3, "tentative_answer": "The Secret Garden]", "uncertainty": 1.6, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3687, "step_index": 4, "tentative_answer": "The Secret Garden]", "uncertainty": 1.6, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3687, "step_index": 5, "tentative_answer": "The Double Life of Veronique]", "uncertainty": 2.19, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3687, "step_index": 6, "tentative_answer": "The Secret Garden]", "uncertainty": 1.6, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3687, "step_index": 7, "tentative_answer": "From 1995 to 1999, Jacob made a series of American and European films that met with varying degrees of commercial and critical success", "uncertainty": 3.46, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6238, "step_index": 1, "tentative_answer": "Wendy Schaal]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6238, "step_index": 2, "tentative_answer": "Wendy Schaal]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6238, "step_index": 3, "tentative_answer": "American Dad!]", "uncertainty": 1.79, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6238, "step_index": 4, "tentative_answer": "Seth MacFarlane, Mike Barker, Matt Weitzman]", "uncertainty": 2.89, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6238, "step_index": 5, "tentative_answer": "Seth MacFarlane, Mike Barker and Matt Weitzman]", "uncertainty": 2.89, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1557, "step_index": 1, "tentative_answer": "birds]", "uncertainty": 1.09, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1557, "step_index": 2, "tentative_answer": "duck]", "uncertainty": 1.09, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1557, "step_index": 3, "tentative_answer": "bird]", "uncertainty": 0.69, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1557, "step_index": 4, "tentative_answer": "bird]", "uncertainty": 0.69, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1557, "step_index": 5, "tentative_answer": "bird]", "uncertainty": 0.69, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1557, "step_index": 6, "tentative_answer": "bird]", "uncertainty": 0.69, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1557, "step_index": 7, "tentative_answer": "bird]", "uncertainty": 0.69, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5762, "step_index": 1, "tentative_answer": "I don't know]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5762, "step_index": 2, "tentative_answer": "Omar Bradley]", "uncertainty": 1.79, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5762, "step_index": 3, "tentative_answer": "Joint Chiefs of Staff]", "uncertainty": 2.08, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5762, "step_index": 4, "tentative_answer": "the Joint Chiefs of Staff]", "uncertainty": 2.2, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2811, "step_index": 1, "tentative_answer": "unknown]", "uncertainty": 0.68, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2811, "step_index": 2, "tentative_answer": "LuxAnimation]", "uncertainty": 1.38, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2811, "step_index": 3, "tentative_answer": "Nelvana Entertainment]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2811, "step_index": 4, "tentative_answer": "Nelvana]", "uncertainty": 1.6, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2811, "step_index": 5, "tentative_answer": "Nelvana Limited]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2811, "step_index": 6, "tentative_answer": "Nelvana Limited]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2811, "step_index": 7, "tentative_answer": "Nelvana]", "uncertainty": 1.6, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1560, "step_index": 1, "tentative_answer": "Shillong]", "uncertainty": 1.38, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1560, "step_index": 2, "tentative_answer": "143,229]", "uncertainty": 2.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1560, "step_index": 3, "tentative_answer": "143,229]", "uncertainty": 2.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2609, "step_index": 1, "tentative_answer": "Tiffany & Co.]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2609, "step_index": 2, "tentative_answer": "Tiffany & Co.]", "uncertainty": 1.95, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2609, "step_index": 3, "tentative_answer": "Tiffany & Co.]", "uncertainty": 1.95, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2609, "step_index": 4, "tentative_answer": "Tiffany & Co.]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2609, "step_index": 5, "tentative_answer": "Tiffany & Co.]", "uncertainty": 1.95, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2609, "step_index": 6, "tentative_answer": "Tiffany & Co.]", "uncertainty": 1.95, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2609, "step_index": 7, "tentative_answer": "Tiffany & Co.]", "uncertainty": 1.95, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3395, "step_index": 1, "tentative_answer": "Lemhi Shoshone]", "uncertainty": 2.07, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3395, "step_index": 2, "tentative_answer": "Shoshone]", "uncertainty": 1.38, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3395, "step_index": 3, "tentative_answer": "Shoshone]", "uncertainty": 1.39, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3395, "step_index": 4, "tentative_answer": "Shoshone]", "uncertainty": 1.39, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5123, "step_index": 1, "tentative_answer": "House of Habsburg-Lorraine]", "uncertainty": 2.48, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5123, "step_index": 2, "tentative_answer": "House of Habsburg-Lorraine]", "uncertainty": 2.48, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5123, "step_index": 3, "tentative_answer": "House of Habsburg-Lorraine]", "uncertainty": 2.48, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3265, "step_index": 1, "tentative_answer": "Homestead National Monument of America, Everglades National Park]", "uncertainty": 2.77, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3265, "step_index": 2, "tentative_answer": "Biscayne National Park, Everglades National Park]", "uncertainty": 2.64, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3265, "step_index": 3, "tentative_answer": "Biscayne National Park, Everglades National Park]", "uncertainty": 2.64, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3265, "step_index": 4, "tentative_answer": "South Carolina, North Carolina]", "uncertainty": 2.07, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3265, "step_index": 5, "tentative_answer": "Great Smoky Mountains National Park, Biscayne National Park]", "uncertainty": 2.89, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3265, "step_index": 6, "tentative_answer": "Southern United States]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3265, "step_index": 7, "tentative_answer": "Southern United States]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3618, "step_index": 1, "tentative_answer": "no]", "uncertainty": 0.68, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3618, "step_index": 2, "tentative_answer": "no]", "uncertainty": 0.68, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3618, "step_index": 3, "tentative_answer": "the Bible is the written Word of God, and because it is inspired throughout, all its assertions are historically and scientifically true in all the original aut", "uncertainty": 3.47, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3618, "step_index": 4, "tentative_answer": "the Bible is the written Word of God, and because it is inspired throughout, all its assertions are historically and scientifically true in all the original aut", "uncertainty": 3.46, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3618, "step_index": 5, "tentative_answer": "the Bible is the written Word of God, and because it is inspired throughout, all its assertions are historically and scientifically true in all the original aut", "uncertainty": 3.46, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3618, "step_index": 6, "tentative_answer": "the Earth and its lifeforms were created by supernatural acts of the Abrahamic God between about 10,000 and 6,00", "uncertainty": 3.47, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 851, "step_index": 1, "tentative_answer": "Could not find Value Alliance airline. Similar: ['Value Alliance', 'Airline alliance', 'Oneworld (redirect from One World (air", "uncertainty": 3.46, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 851, "step_index": 2, "tentative_answer": "Value Alliance]", "uncertainty": 1.38, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 851, "step_index": 3, "tentative_answer": "Cebu Pacific]", "uncertainty": 1.79, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 851, "step_index": 4, "tentative_answer": "Cebgo]", "uncertainty": 1.39, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 851, "step_index": 5, "tentative_answer": "Jeju Air]", "uncertainty": 1.61, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 851, "step_index": 6, "tentative_answer": "Cebu Pacific]", "uncertainty": 1.79, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 851, "step_index": 7, "tentative_answer": "Cebu Pacific]", "uncertainty": 1.79, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4678, "step_index": 1, "tentative_answer": "unknown]", "uncertainty": 0.68, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4678, "step_index": 2, "tentative_answer": "US Navy]", "uncertainty": 1.37, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4678, "step_index": 3, "tentative_answer": "336,978]", "uncertainty": 2.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4678, "step_index": 4, "tentative_answer": "336,978]", "uncertainty": 2.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 457, "step_index": 1, "tentative_answer": "Frigg]", "uncertainty": 1.38, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 457, "step_index": 2, "tentative_answer": "Frigg]", "uncertainty": 1.38, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 457, "step_index": 3, "tentative_answer": "Fulla, Lofn, Hlín, Gná, and ambiguously with the Earth]", "uncertainty": 3.13, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 457, "step_index": 4, "tentative_answer": "Fulla, Lofn, Hlín, Gná, and the Earth]", "uncertainty": 2.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 457, "step_index": 5, "tentative_answer": "Fulla, Lofn, Hlín, Gná, and the Earth]", "uncertainty": 2.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 457, "step_index": 6, "tentative_answer": "Fulla, Lofn, Hlín, Gná]", "uncertainty": 2.71, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 457, "step_index": 7, "tentative_answer": "Fulla, Lofn, Hlín, Gná, and the Earth]", "uncertainty": 2.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1439, "step_index": 1, "tentative_answer": "yes]", "uncertainty": 0.68, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1439, "step_index": 2, "tentative_answer": "yes]", "uncertainty": 0.69, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1439, "step_index": 3, "tentative_answer": "yes]", "uncertainty": 0.69, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6849, "step_index": 1, "tentative_answer": "The World Games are an international multi-sport event comprising sports and sporting disciplines that are not contested in the Olympic Games. They are usually", "uncertainty": 3.46, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6849, "step_index": 2, "tentative_answer": "2021]", "uncertainty": 1.61, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6849, "step_index": 3, "tentative_answer": "2024 Summer Olympics]", "uncertainty": 2.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6849, "step_index": 4, "tentative_answer": "2020 Summer Olympics]", "uncertainty": 2.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6849, "step_index": 5, "tentative_answer": "2016 Summer Olympics]", "uncertainty": 2.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6849, "step_index": 6, "tentative_answer": "2012 Summer Olympics]", "uncertainty": 2.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6849, "step_index": 7, "tentative_answer": "b the 2008.", "uncertainty": 2.19, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6800, "step_index": 1, "tentative_answer": "the Pacific Ocean]", "uncertainty": 1.6, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6800, "step_index": 2, "tentative_answer": "165,250,000 square kilometers]", "uncertainty": 2.77, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6800, "step_index": 3, "tentative_answer": "165,250,000 square kilometers]", "uncertainty": 2.77, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1781, "step_index": 1, "tentative_answer": "Dark Horse]", "uncertainty": 1.78, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1781, "step_index": 2, "tentative_answer": "Dark Horse (album)]", "uncertainty": 2.07, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1781, "step_index": 3, "tentative_answer": "North American tour]", "uncertainty": 1.79, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1781, "step_index": 4, "tentative_answer": "North American tour]", "uncertainty": 1.79, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 7260, "step_index": 1, "tentative_answer": "I don't know]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 7260, "step_index": 2, "tentative_answer": "2011]", "uncertainty": 1.6, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 7260, "step_index": 3, "tentative_answer": "I don't know]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 7260, "step_index": 4, "tentative_answer": "I don't know]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 7260, "step_index": 5, "tentative_answer": "I don't know]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 7260, "step_index": 6, "tentative_answer": "I don't know]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 7260, "step_index": 7, "tentative_answer": "I don't know]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1224, "step_index": 1, "tentative_answer": "Raymond Yip Wai-man]", "uncertainty": 2.39, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1224, "step_index": 2, "tentative_answer": "I don't know]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1224, "step_index": 3, "tentative_answer": "Michelle Reis]", "uncertainty": 1.79, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1224, "step_index": 4, "tentative_answer": "Michelle Reis]", "uncertainty": 1.79, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1224, "step_index": 5, "tentative_answer": "yes]", "uncertainty": 0.68, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1224, "step_index": 6, "tentative_answer": "The Lovers]", "uncertainty": 1.61, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6669, "step_index": 1, "tentative_answer": "I don't know]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6669, "step_index": 2, "tentative_answer": "Jaśmina Tremer]", "uncertainty": 2.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6669, "step_index": 3, "tentative_answer": "Kansas Joe McCoy and Memphis Minnie]", "uncertainty": 2.64, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5630, "step_index": 1, "tentative_answer": "Philadelphia Phillies]", "uncertainty": 2.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5630, "step_index": 2, "tentative_answer": "Oakland Athletics]", "uncertainty": 1.79, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5630, "step_index": 3, "tentative_answer": "Oakland Athletics]", "uncertainty": 1.79, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 416, "step_index": 1, "tentative_answer": "Krusty the Clown]", "uncertainty": 2.2, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 416, "step_index": 2, "tentative_answer": "Krusty the Clown]", "uncertainty": 2.2, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 416, "step_index": 3, "tentative_answer": "The Krusty the Clown Show]", "uncertainty": 2.4, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 7100, "step_index": 1, "tentative_answer": "musician, producer, record label owner]", "uncertainty": 2.3, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 7100, "step_index": 2, "tentative_answer": "musician]", "uncertainty": 1.1, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 7100, "step_index": 3, "tentative_answer": "singer]", "uncertainty": 1.1, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1107, "step_index": 1, "tentative_answer": "Philadelphia, Pennsylvania]", "uncertainty": 2.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1107, "step_index": 2, "tentative_answer": "University of Maryland University College]", "uncertainty": 2.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1107, "step_index": 3, "tentative_answer": "College Park, Maryland]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2287, "step_index": 1, "tentative_answer": "Lucie Hradecká]", "uncertainty": 2.2, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2287, "step_index": 2, "tentative_answer": "Lucie Hradecká]", "uncertainty": 2.2, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2287, "step_index": 3, "tentative_answer": "yes]", "uncertainty": 0.69, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3725, "step_index": 1, "tentative_answer": "Mariaan de Swardt]", "uncertainty": 2.2, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3725, "step_index": 2, "tentative_answer": "Mariaan de Swardt]", "uncertainty": 2.2, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3725, "step_index": 3, "tentative_answer": "Mariaan de Swardt]", "uncertainty": 2.2, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5071, "step_index": 1, "tentative_answer": "The Color Purple]", "uncertainty": 1.79, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5071, "step_index": 2, "tentative_answer": "Celie]", "uncertainty": 1.39, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5071, "step_index": 3, "tentative_answer": "Celie]", "uncertainty": 1.38, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3750, "step_index": 1, "tentative_answer": "Jennifer Kent]", "uncertainty": 1.79, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3750, "step_index": 2, "tentative_answer": "Jennifer Kent]", "uncertainty": 1.79, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3750, "step_index": 3, "tentative_answer": "Kristina Ceyton and Kristian Moliere]", "uncertainty": 2.64, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2559, "step_index": 1, "tentative_answer": "Presidio of San Francisco]", "uncertainty": 2.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2559, "step_index": 2, "tentative_answer": "Golden Gate National Recreation Area]", "uncertainty": 2.4, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2559, "step_index": 3, "tentative_answer": "Golden Gate National Recreation Area]", "uncertainty": 2.4, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5426, "step_index": 1, "tentative_answer": "no answer]", "uncertainty": 1.38, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5426, "step_index": 2, "tentative_answer": "Kiss]", "uncertainty": 1.1, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5426, "step_index": 3, "tentative_answer": "Kiss]", "uncertainty": 1.1, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3473, "step_index": 1, "tentative_answer": "Charcoal Tank Nature Reserve]", "uncertainty": 2.19, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3473, "step_index": 2, "tentative_answer": "no answer]", "uncertainty": 1.37, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3473, "step_index": 3, "tentative_answer": "Newell Highway]", "uncertainty": 1.6, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3473, "step_index": 4, "tentative_answer": "Newell Highway]", "uncertainty": 1.6, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3473, "step_index": 5, "tentative_answer": "Newell Highway]", "uncertainty": 1.6, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3473, "step_index": 6, "tentative_answer": "Newell Highway]", "uncertainty": 1.6, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3473, "step_index": 7, "tentative_answer": "Newell Highway]", "uncertainty": 1.6, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 7390, "step_index": 1, "tentative_answer": "I don't know]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 7390, "step_index": 2, "tentative_answer": "Barbara Bush]", "uncertainty": 1.6, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 7390, "step_index": 3, "tentative_answer": "George H. W. Bush]", "uncertainty": 2.19, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 7390, "step_index": 4, "tentative_answer": "George W. Bush]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 7390, "step_index": 5, "tentative_answer": "Barbara Bush]", "uncertainty": 1.6, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 7390, "step_index": 6, "tentative_answer": "Barbara Bush]", "uncertainty": 1.6, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 7390, "step_index": 7, "tentative_answer": "Barbara Bush]", "uncertainty": 1.6, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3738, "step_index": 1, "tentative_answer": "English Civil War]", "uncertainty": 1.61, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3738, "step_index": 2, "tentative_answer": "Royalists and Parliamentarians]", "uncertainty": 2.2, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3738, "step_index": 3, "tentative_answer": "Royalists and Parliamentarians]", "uncertainty": 2.2, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 7136, "step_index": 1, "tentative_answer": "Las Vegas]", "uncertainty": 1.79, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 7136, "step_index": 2, "tentative_answer": "Paradise, Nevada]", "uncertainty": 2.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3531, "step_index": 1, "tentative_answer": "Cannes Film Festival Award for Best Actor]", "uncertainty": 2.4, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3531, "step_index": 2, "tentative_answer": "Golden Globe nomination]", "uncertainty": 2.19, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3531, "step_index": 3, "tentative_answer": "Golden Globe nomination]", "uncertainty": 2.2, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6952, "step_index": 1, "tentative_answer": "Kevin Durant]", "uncertainty": 1.61, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6952, "step_index": 2, "tentative_answer": "National Basketball Association]", "uncertainty": 1.6, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6952, "step_index": 3, "tentative_answer": "NBA Cup]", "uncertainty": 1.61, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6952, "step_index": 4, "tentative_answer": "NBA Cup]", "uncertainty": 1.61, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6952, "step_index": 5, "tentative_answer": "NBA Award]", "uncertainty": 1.6, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6952, "step_index": 6, "tentative_answer": "NBA Rookie of the Year]", "uncertainty": 2.3, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6952, "step_index": 7, "tentative_answer": "National Basketball Association's Rookie of the Year]", "uncertainty": 2.56, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4261, "step_index": 1, "tentative_answer": "1847]", "uncertainty": 1.61, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4261, "step_index": 2, "tentative_answer": "1976]", "uncertainty": 1.61, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4261, "step_index": 3, "tentative_answer": "Paddington (TV series)]", "uncertainty": 2.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4261, "step_index": 4, "tentative_answer": "2014]", "uncertainty": 1.61, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4261, "step_index": 5, "tentative_answer": "2014]", "uncertainty": 1.61, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4261, "step_index": 6, "tentative_answer": "2017]", "uncertainty": 1.61, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4261, "step_index": 7, "tentative_answer": "1976]", "uncertainty": 1.61, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4784, "step_index": 1, "tentative_answer": "Downers Grove is a village in DuPage County, Illinois, United States. It was founded in 1832 by Pierce Downer,", "uncertainty": 3.46, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4784, "step_index": 2, "tentative_answer": "Downers Grove is a village in DuPage County, Illinois, United States. It was founded in 1832 by Pierce Downer,", "uncertainty": 3.46, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4784, "step_index": 3, "tentative_answer": "Downers Grove is a village in DuPage County, Illinois, United States. It was founded in 1832 by Pierce Downer,", "uncertainty": 3.46, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4784, "step_index": 4, "tentative_answer": "The Curse of Downers Grove is a teen angst thriller set in a high school gripped by an apparent curse that claims the", "uncertainty": 3.46, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4784, "step_index": 5, "tentative_answer": "yes]", "uncertainty": 0.69, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 339, "step_index": 1, "tentative_answer": "Arrowhead Stadium]", "uncertainty": 1.78, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 339, "step_index": 2, "tentative_answer": "76,416]", "uncertainty": 1.95, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 339, "step_index": 3, "tentative_answer": "76,416]", "uncertainty": 1.94, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 339, "step_index": 4, "tentative_answer": "37,903]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3388, "step_index": 1, "tentative_answer": "Washington, D.C.]", "uncertainty": 2.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3388, "step_index": 2, "tentative_answer": "Washington, D.C.]", "uncertainty": 2.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3388, "step_index": 3, "tentative_answer": "Washington, D.C.]", "uncertainty": 2.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3388, "step_index": 4, "tentative_answer": "yes]", "uncertainty": 0.69, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2674, "step_index": 1, "tentative_answer": "Israel national football team]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2674, "step_index": 2, "tentative_answer": "1970 FIFA World Cup]", "uncertainty": 2.2, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2674, "step_index": 3, "tentative_answer": "1970 FIFA World Cup]", "uncertainty": 2.2, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2674, "step_index": 4, "tentative_answer": "1970 FIFA World Cup]", "uncertainty": 2.2, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4523, "step_index": 1, "tentative_answer": "no]", "uncertainty": 0.69, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4523, "step_index": 2, "tentative_answer": "Wrath of Gods]", "uncertainty": 2.08, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3491, "step_index": 1, "tentative_answer": "University of Padua]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3491, "step_index": 2, "tentative_answer": "no]", "uncertainty": 0.69, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3491, "step_index": 3, "tentative_answer": "no]", "uncertainty": 0.69, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4745, "step_index": 1, "tentative_answer": "Region of Southern Denmark]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4745, "step_index": 2, "tentative_answer": "municipalities]", "uncertainty": 1.6, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4745, "step_index": 3, "tentative_answer": "agricultural products, fish, tourism]", "uncertainty": 2.48, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 92, "step_index": 1, "tentative_answer": "I don't know]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 92, "step_index": 2, "tentative_answer": "I don't know]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 92, "step_index": 3, "tentative_answer": "unknown]", "uncertainty": 0.68, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 92, "step_index": 4, "tentative_answer": "unknown]", "uncertainty": 0.68, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 92, "step_index": 5, "tentative_answer": "unknown]", "uncertainty": 0.69, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 92, "step_index": 6, "tentative_answer": "unknown]", "uncertainty": 0.69, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 92, "step_index": 7, "tentative_answer": "I don't know]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6237, "step_index": 1, "tentative_answer": "Ulver]", "uncertainty": 1.39, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6237, "step_index": 2, "tentative_answer": "Kristoffer Rygg]", "uncertainty": 2.08, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6237, "step_index": 3, "tentative_answer": "Kristoffer Rygg]", "uncertainty": 2.08, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5199, "step_index": 1, "tentative_answer": "38th César Awards]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5199, "step_index": 2, "tentative_answer": "Amour]", "uncertainty": 1.1, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5199, "step_index": 3, "tentative_answer": "Amour]", "uncertainty": 1.09, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5199, "step_index": 4, "tentative_answer": "Anne and Georges]", "uncertainty": 1.79, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5199, "step_index": 5, "tentative_answer": "Anne and Georges]", "uncertainty": 1.79, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2008, "step_index": 1, "tentative_answer": "journalist]", "uncertainty": 1.38, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2008, "step_index": 2, "tentative_answer": "journalist]", "uncertainty": 1.38, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2008, "step_index": 3, "tentative_answer": "journalist]", "uncertainty": 1.38, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2008, "step_index": 4, "tentative_answer": "journalist]", "uncertainty": 1.38, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2008, "step_index": 5, "tentative_answer": "journalist]", "uncertainty": 1.38, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2008, "step_index": 6, "tentative_answer": "journalist]", "uncertainty": 1.38, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2008, "step_index": 7, "tentative_answer": "journalist]", "uncertainty": 1.38, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5704, "step_index": 1, "tentative_answer": "unknown]", "uncertainty": 0.68, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5704, "step_index": 2, "tentative_answer": "Alan Tudyk]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5704, "step_index": 3, "tentative_answer": "Alan Tudyk]", "uncertainty": 1.95, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4274, "step_index": 1, "tentative_answer": "Walter Röhrl]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4274, "step_index": 2, "tentative_answer": "Fiat, Opel, Lancia, and Audi]", "uncertainty": 2.64, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4274, "step_index": 3, "tentative_answer": "Fiat, Opel, Lancia, and Audi]", "uncertainty": 2.64, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1949, "step_index": 1, "tentative_answer": "Brian Phillip Curran]", "uncertainty": 2.07, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1949, "step_index": 2, "tentative_answer": "Brian Curran (New York politician)]", "uncertainty": 2.3, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1949, "step_index": 3, "tentative_answer": "Lynbrook, Valley Stream, Rockville Centre, South Hempstead and portions of Baldwin, Oceanside, East Rockaway", "uncertainty": 3.47, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1949, "step_index": 4, "tentative_answer": "Lynbrook]", "uncertainty": 1.61, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4551, "step_index": 1, "tentative_answer": "I don't know]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4551, "step_index": 2, "tentative_answer": "Collier County]", "uncertainty": 1.61, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4551, "step_index": 3, "tentative_answer": "375,752]", "uncertainty": 2.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4551, "step_index": 4, "tentative_answer": "375,752]", "uncertainty": 2.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2672, "step_index": 1, "tentative_answer": "Tokugawa shogunate]", "uncertainty": 2.3, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2672, "step_index": 2, "tentative_answer": "Tokugawa shogunate]", "uncertainty": 2.3, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5472, "step_index": 1, "tentative_answer": "Guadalajara]", "uncertainty": 1.6, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5472, "step_index": 2, "tentative_answer": "no answer]", "uncertainty": 1.37, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5472, "step_index": 3, "tentative_answer": "no answer]", "uncertainty": 1.37, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5472, "step_index": 4, "tentative_answer": "I don't know]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5472, "step_index": 5, "tentative_answer": "I don't know]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5472, "step_index": 6, "tentative_answer": "I don't know]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5472, "step_index": 7, "tentative_answer": "I don't know]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5504, "step_index": 1, "tentative_answer": "East African Breweries]", "uncertainty": 2.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5504, "step_index": 2, "tentative_answer": "East African Breweries]", "uncertainty": 2.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5504, "step_index": 3, "tentative_answer": "Kenya]", "uncertainty": 1.38, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4104, "step_index": 1, "tentative_answer": "Bamburgh Castle]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4104, "step_index": 2, "tentative_answer": "Bamburgh Castle]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4104, "step_index": 3, "tentative_answer": "Bamburgh Castle, Lindisfarne, Viking invasion of 789, North East England, Gryphaea]", "uncertainty": 3.43, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4104, "step_index": 4, "tentative_answer": "North West England, North East England]", "uncertainty": 2.3, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4104, "step_index": 5, "tentative_answer": "North West England, Yorkshire and the Humber]", "uncertainty": 2.56, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4104, "step_index": 6, "tentative_answer": "Bamburgh Castle, Warkworth Castle, Dunstanburgh Castle, Alnwick Castle, Lindisfarne Castle, Tynemouth", "uncertainty": 3.46, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4104, "step_index": 7, "tentative_answer": "West Midlands]", "uncertainty": 1.6, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 88, "step_index": 1, "tentative_answer": "unknown]", "uncertainty": 0.69, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 88, "step_index": 2, "tentative_answer": "I don't know]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 88, "step_index": 3, "tentative_answer": "unknown]", "uncertainty": 0.68, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 88, "step_index": 4, "tentative_answer": "300 million]", "uncertainty": 1.79, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4543, "step_index": 1, "tentative_answer": "I don't know]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4543, "step_index": 2, "tentative_answer": "I don't know]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4543, "step_index": 3, "tentative_answer": "I don't know]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4543, "step_index": 4, "tentative_answer": "I don't know]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4543, "step_index": 5, "tentative_answer": "I don't know]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4543, "step_index": 6, "tentative_answer": "I don't know]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4543, "step_index": 7, "tentative_answer": "I don't know]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5234, "step_index": 1, "tentative_answer": "United Airlines Flight 93]", "uncertainty": 2.3, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5234, "step_index": 2, "tentative_answer": "United Airlines Flight 93]", "uncertainty": 2.3, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5234, "step_index": 3, "tentative_answer": "Shanksville in Somerset County, Pennsylvania]", "uncertainty": 2.4, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5234, "step_index": 4, "tentative_answer": "Shanksville in Somerset County, Pennsylvania]", "uncertainty": 2.4, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5234, "step_index": 5, "tentative_answer": "Shanksville in Somerset County, Pennsylvania]", "uncertainty": 2.4, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3808, "step_index": 1, "tentative_answer": "Dominique Wilkins]", "uncertainty": 1.95, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3808, "step_index": 2, "tentative_answer": "Los Angeles Clippers, Boston Celtics, Panathinaikos, Fortitudo Bologna, San Antonio Spurs, Orlando Magic]", "uncertainty": 3.47, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3808, "step_index": 3, "tentative_answer": "Orlando Magic]", "uncertainty": 1.61, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3465, "step_index": 1, "tentative_answer": "no answer]", "uncertainty": 1.37, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3465, "step_index": 2, "tentative_answer": "Belgium, France, Russia, United Kingdom]", "uncertainty": 2.48, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3465, "step_index": 3, "tentative_answer": "Belgium, France, Russia, United Kingdom]", "uncertainty": 2.48, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5486, "step_index": 1, "tentative_answer": "Hunchun]", "uncertainty": 1.38, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5486, "step_index": 2, "tentative_answer": "Hunchun]", "uncertainty": 1.38, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5486, "step_index": 3, "tentative_answer": "Hunchun]", "uncertainty": 1.39, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1945, "step_index": 1, "tentative_answer": "MGP Ingredients]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1945, "step_index": 2, "tentative_answer": "Lawrenceburg, Indiana]", "uncertainty": 2.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1945, "step_index": 3, "tentative_answer": "Atchison, Kansas]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1945, "step_index": 4, "tentative_answer": "Atchison, Kansas]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1538, "step_index": 1, "tentative_answer": "14th century]", "uncertainty": 1.79, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1538, "step_index": 2, "tentative_answer": "1206–1526]", "uncertainty": 2.3, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1538, "step_index": 3, "tentative_answer": "1206 to 1526]", "uncertainty": 2.48, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2711, "step_index": 1, "tentative_answer": "Battle of Gettysburg]", "uncertainty": 2.2, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2711, "step_index": 2, "tentative_answer": "Battle of Gettysburg]", "uncertainty": 2.2, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2711, "step_index": 3, "tentative_answer": "yes]", "uncertainty": 0.69, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3991, "step_index": 1, "tentative_answer": "Middlesbrough F.C.]", "uncertainty": 2.3, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3991, "step_index": 2, "tentative_answer": "Middlesbrough F.C.]", "uncertainty": 2.3, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 3991, "step_index": 3, "tentative_answer": "Middlesbrough F.C.]", "uncertainty": 2.3, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5925, "step_index": 1, "tentative_answer": "Oregon Territory]", "uncertainty": 1.79, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5925, "step_index": 2, "tentative_answer": "Oregon Territory]", "uncertainty": 1.79, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5925, "step_index": 3, "tentative_answer": "August 14, 1848, until February 14, 1859]", "uncertainty": 3.18, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6166, "step_index": 1, "tentative_answer": "Doug Basham]", "uncertainty": 1.79, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6166, "step_index": 2, "tentative_answer": "United States Wrestling Association]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6166, "step_index": 3, "tentative_answer": "yes]", "uncertainty": 0.69, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 816, "step_index": 1, "tentative_answer": "Richard Williams (tennis coach)]", "uncertainty": 2.19, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 816, "step_index": 2, "tentative_answer": "Serena Williams]", "uncertainty": 1.6, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 816, "step_index": 3, "tentative_answer": "unknown]", "uncertainty": 0.69, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 816, "step_index": 4, "tentative_answer": "no]", "uncertainty": 0.69, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 816, "step_index": 5, "tentative_answer": "University of Northern Ireland]", "uncertainty": 1.95, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4660, "step_index": 1, "tentative_answer": "singer, songwriter]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4660, "step_index": 2, "tentative_answer": "singer, songwriter]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4660, "step_index": 3, "tentative_answer": "singer, songwriter, guitarist, producer]", "uncertainty": 2.48, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 734, "step_index": 1, "tentative_answer": "unknown]", "uncertainty": 0.68, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 734, "step_index": 2, "tentative_answer": "Pearl Brewing Company]", "uncertainty": 2.19, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 734, "step_index": 3, "tentative_answer": "Miller Brewing]", "uncertainty": 1.94, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 734, "step_index": 4, "tentative_answer": "Miller Brewing]", "uncertainty": 1.94, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2934, "step_index": 1, "tentative_answer": "Ray \"Crash\" Corrigan]", "uncertainty": 2.4, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2934, "step_index": 2, "tentative_answer": "Dr. Brewster M. Higley]", "uncertainty": 2.48, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2934, "step_index": 3, "tentative_answer": "Dr. Brewster M. Higley]", "uncertainty": 2.48, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5720, "step_index": 1, "tentative_answer": "The state may pursue justice by operating courts and enforcing their rulings.]", "uncertainty": 2.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5720, "step_index": 2, "tentative_answer": "November 1983]", "uncertainty": 2.19, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5720, "step_index": 3, "tentative_answer": "no]", "uncertainty": 0.68, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5720, "step_index": 4, "tentative_answer": "WWE]", "uncertainty": 1.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5720, "step_index": 5, "tentative_answer": "no answer]", "uncertainty": 1.37, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5720, "step_index": 6, "tentative_answer": "no]", "uncertainty": 0.67, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5720, "step_index": 7, "tentative_answer": "no]", "uncertainty": 0.67, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2401, "step_index": 1, "tentative_answer": "The Shins]", "uncertainty": 1.61, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2401, "step_index": 2, "tentative_answer": "The Shins]", "uncertainty": 1.61, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2401, "step_index": 3, "tentative_answer": "The Shins]", "uncertainty": 1.61, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1187, "step_index": 1, "tentative_answer": "Apalachee]", "uncertainty": 1.6, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1187, "step_index": 2, "tentative_answer": "Apalachee]", "uncertainty": 1.61, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1187, "step_index": 3, "tentative_answer": "Apalachee]", "uncertainty": 1.61, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1621, "step_index": 1, "tentative_answer": "Beauty and the Beast (1991 film)]", "uncertainty": 2.71, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1621, "step_index": 2, "tentative_answer": "Beauty and the Beast (1991 film)]", "uncertainty": 2.71, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1621, "step_index": 3, "tentative_answer": "Beauty and the Beast (1946 film)]", "uncertainty": 2.71, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1621, "step_index": 4, "tentative_answer": "Beauty and the Beast (1991 film)]", "uncertainty": 2.71, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1621, "step_index": 5, "tentative_answer": "Beauty and the Beast (1946 film)]", "uncertainty": 2.71, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6406, "step_index": 1, "tentative_answer": "Maze Runner film trilogy]", "uncertainty": 2.3, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6406, "step_index": 2, "tentative_answer": "no]", "uncertainty": 0.69, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6406, "step_index": 3, "tentative_answer": "music]", "uncertainty": 0.69, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4923, "step_index": 1, "tentative_answer": "Schapendoes]", "uncertainty": 1.6, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4923, "step_index": 2, "tentative_answer": "Bull Terrier]", "uncertainty": 1.79, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4923, "step_index": 3, "tentative_answer": "Schapendoes]", "uncertainty": 1.61, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2648, "step_index": 1, "tentative_answer": "18-year-old Deryl Dedmon of Brandon]", "uncertainty": 2.83, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2648, "step_index": 2, "tentative_answer": "23,218]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2648, "step_index": 3, "tentative_answer": "25,138]", "uncertainty": 1.95, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2648, "step_index": 4, "tentative_answer": "25,138]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6249, "step_index": 1, "tentative_answer": "Jason Dolley]", "uncertainty": 1.79, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6249, "step_index": 2, "tentative_answer": "Jason Dolley]", "uncertainty": 1.79, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6249, "step_index": 3, "tentative_answer": "Bridgit Mendler]", "uncertainty": 2.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6249, "step_index": 4, "tentative_answer": "Bradley Steven Perry]", "uncertainty": 1.95, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6249, "step_index": 5, "tentative_answer": "Leigh-Allyn Baker]", "uncertainty": 2.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6249, "step_index": 6, "tentative_answer": "Eric Allan Kramer]", "uncertainty": 2.2, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6249, "step_index": 7, "tentative_answer": "Patricia Belcher]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4646, "step_index": 1, "tentative_answer": "I don't know]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4646, "step_index": 2, "tentative_answer": "I don't know]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4646, "step_index": 3, "tentative_answer": "If the deceased was judged worthy, his or her ka and ba were united into an akh. Several beliefs coexisted about the ak", "uncertainty": 3.46, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4646, "step_index": 4, "tentative_answer": "no]", "uncertainty": 0.67, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4646, "step_index": 5, "tentative_answer": "I don't know]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4646, "step_index": 6, "tentative_answer": "I don't know]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4646, "step_index": 7, "tentative_answer": "Lake of fire]", "uncertainty": 1.79, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1466, "step_index": 1, "tentative_answer": "Daisy Chainsaw]", "uncertainty": 2.08, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1466, "step_index": 2, "tentative_answer": "Daisy Chainsaw]", "uncertainty": 2.08, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1466, "step_index": 3, "tentative_answer": "Daisy Chainsaw]", "uncertainty": 2.08, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 891, "step_index": 1, "tentative_answer": "Ulf Merbold]", "uncertainty": 1.95, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 891, "step_index": 2, "tentative_answer": "Ulf Merbold]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 891, "step_index": 3, "tentative_answer": "Mirosław Hermaszewski]", "uncertainty": 2.2, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6174, "step_index": 1, "tentative_answer": "no answer]", "uncertainty": 1.37, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6174, "step_index": 2, "tentative_answer": "Division I]", "uncertainty": 1.61, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6174, "step_index": 3, "tentative_answer": "NCAA]", "uncertainty": 1.1, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6174, "step_index": 4, "tentative_answer": "Division I]", "uncertainty": 1.61, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6174, "step_index": 5, "tentative_answer": "Division I competition]", "uncertainty": 1.79, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6174, "step_index": 6, "tentative_answer": "NCAA]", "uncertainty": 1.1, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6174, "step_index": 7, "tentative_answer": "NCAA]", "uncertainty": 1.09, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2988, "step_index": 1, "tentative_answer": "Texas Longhorns]", "uncertainty": 1.95, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2988, "step_index": 2, "tentative_answer": "Texas Longhorns]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2988, "step_index": 3, "tentative_answer": "Texas Longhorns]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 291, "step_index": 1, "tentative_answer": "no answer]", "uncertainty": 1.37, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 291, "step_index": 2, "tentative_answer": "Cleveland]", "uncertainty": 1.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 291, "step_index": 3, "tentative_answer": "Interstate 81 in Virginia]", "uncertainty": 2.19, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 291, "step_index": 4, "tentative_answer": "324.92 miles]", "uncertainty": 2.19, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 291, "step_index": 5, "tentative_answer": "no answer]", "uncertainty": 1.37, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 291, "step_index": 6, "tentative_answer": "324.92 miles]", "uncertainty": 2.19, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 291, "step_index": 7, "tentative_answer": "unknown]", "uncertainty": 0.66, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2261, "step_index": 1, "tentative_answer": "Blessid Union of Souls]", "uncertainty": 2.2, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2261, "step_index": 2, "tentative_answer": "Blessid Union of Souls]", "uncertainty": 2.2, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2261, "step_index": 3, "tentative_answer": "Blessid Union of Souls]", "uncertainty": 2.2, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2545, "step_index": 1, "tentative_answer": "Drive]", "uncertainty": 1.09, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2545, "step_index": 2, "tentative_answer": "Drive]", "uncertainty": 1.09, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2545, "step_index": 3, "tentative_answer": "Drive (Incubus song)]", "uncertainty": 2.3, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2545, "step_index": 4, "tentative_answer": "Drive by Incubus]", "uncertainty": 2.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2545, "step_index": 5, "tentative_answer": "Drive by Incubus]", "uncertainty": 2.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2545, "step_index": 6, "tentative_answer": "Drive by Incubus]", "uncertainty": 2.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2545, "step_index": 7, "tentative_answer": "Drive by Incubus]", "uncertainty": 2.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5962, "step_index": 1, "tentative_answer": "no]", "uncertainty": 0.69, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5962, "step_index": 2, "tentative_answer": "yes]", "uncertainty": 0.68, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5962, "step_index": 3, "tentative_answer": "yes]", "uncertainty": 0.69, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5063, "step_index": 1, "tentative_answer": "Theodoros]", "uncertainty": 1.39, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5063, "step_index": 2, "tentative_answer": "Theodoros]", "uncertainty": 1.39, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5063, "step_index": 3, "tentative_answer": "Theo Angelopoulos]", "uncertainty": 2.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5726, "step_index": 1, "tentative_answer": "1940s and 1950s]", "uncertainty": 2.64, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5726, "step_index": 2, "tentative_answer": "1940s and 1950s]", "uncertainty": 2.64, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5726, "step_index": 3, "tentative_answer": "1940s and 1950s]", "uncertainty": 2.64, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1636, "step_index": 1, "tentative_answer": "Gábor Csupó]", "uncertainty": 2.08, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1636, "step_index": 2, "tentative_answer": "Klasky Csupo]", "uncertainty": 2.2, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 1636, "step_index": 3, "tentative_answer": "Klasky Csupo]", "uncertainty": 2.2, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6518, "step_index": 1, "tentative_answer": "Greater Rochester International Airport]", "uncertainty": 2.08, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6518, "step_index": 2, "tentative_answer": "Greater Rochester International Airport]", "uncertainty": 2.08, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6518, "step_index": 3, "tentative_answer": "Greater Rochester International Airport]", "uncertainty": 2.08, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6324, "step_index": 1, "tentative_answer": "architect]", "uncertainty": 1.09, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6324, "step_index": 2, "tentative_answer": "no]", "uncertainty": 0.68, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6324, "step_index": 3, "tentative_answer": "unknown]", "uncertainty": 0.68, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6324, "step_index": 4, "tentative_answer": "unknown]", "uncertainty": 0.68, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6324, "step_index": 5, "tentative_answer": "unknown]", "uncertainty": 0.68, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6324, "step_index": 6, "tentative_answer": "unknown]", "uncertainty": 0.68, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6324, "step_index": 7, "tentative_answer": "unknown]", "uncertainty": 0.68, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2864, "step_index": 1, "tentative_answer": "Bart Conner]", "uncertainty": 1.79, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2864, "step_index": 2, "tentative_answer": "Bart Conner]", "uncertainty": 1.79, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 319, "step_index": 1, "tentative_answer": "Bressie, Sharon Corr, Kian Egan and Brian Kennedy]", "uncertainty": 2.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 319, "step_index": 2, "tentative_answer": "The Voice of Ireland is an Irish reality talent show. It began airing on 8 January 2012. It replaced The All Ireland Tal", "uncertainty": 3.46, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 319, "step_index": 3, "tentative_answer": "no]", "uncertainty": 0.68, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 319, "step_index": 4, "tentative_answer": "The Voice of Ireland (series 3)]", "uncertainty": 2.39, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 319, "step_index": 5, "tentative_answer": "The Voice of Ireland (series 4)]", "uncertainty": 2.39, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 319, "step_index": 6, "tentative_answer": "Bressie, Kian Egan]", "uncertainty": 2.3, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 319, "step_index": 7, "tentative_answer": "no]", "uncertainty": 0.68, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5939, "step_index": 1, "tentative_answer": "I don't know]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5939, "step_index": 2, "tentative_answer": "Len Berman, Tim McCarver, Barry Tompkins, Bob Gibson, Maury Wills]", "uncertainty": 3.22, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5939, "step_index": 3, "tentative_answer": "no]", "uncertainty": 0.69, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5939, "step_index": 4, "tentative_answer": "no]", "uncertainty": 0.69, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5939, "step_index": 5, "tentative_answer": "no]", "uncertainty": 0.69, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5939, "step_index": 6, "tentative_answer": "no]", "uncertainty": 0.69, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 5939, "step_index": 7, "tentative_answer": "no]", "uncertainty": 0.69, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6626, "step_index": 1, "tentative_answer": "Alex Rodriguez]", "uncertainty": 1.79, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6626, "step_index": 2, "tentative_answer": "Baseball Writers' Association of America]", "uncertainty": 2.3, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6626, "step_index": 3, "tentative_answer": "Baseball Writers' Association of America]", "uncertainty": 2.3, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 6626, "step_index": 4, "tentative_answer": "Baseball Writers' Association of America and Hillerich & Bradsby]", "uncertainty": 2.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2150, "step_index": 1, "tentative_answer": "director, producer]", "uncertainty": 1.79, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2150, "step_index": 2, "tentative_answer": "director, screenwriter]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 2150, "step_index": 3, "tentative_answer": "director, screenwriter]", "uncertainty": 1.94, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4744, "step_index": 1, "tentative_answer": "rock and roll]", "uncertainty": 1.6, "threshold": 1.79, "em": true}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4744, "step_index": 2, "tentative_answer": "blues, rock and roll, rhythm and blues]", "uncertainty": 2.64, "threshold": 1.79, "em": false}
{"dataset": "HotpotQA", "model": "meta-llama/Llama-2-70b-hf", "mode": "uala_step_eval", "question_idx": 4744, "step_index": 3, "tentative_answer": "blues, rock and roll, rhythm and blues]", "uncertainty": 2.64, "threshold": 1.79, "em": false}
